{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Purpose \n",
    "\n",
    "\n",
    "The purpose of this notebook is mainly to collect the training and testing data that will be used for building and evaluating the model. Data was collected using OpenCV, by accessing the webcam and then extracting the landmarks from Mediapipe. This data was then saved into the \"data\" array. Corresponding labels were also saved which would be used for the classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Relevant Notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools \n",
    "import random\n",
    "import os \n",
    "\n",
    "import csv \n",
    "from collections import Counter \n",
    "from collections import deque\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to be implemented \n",
    "\n",
    "1. Access webcam with Opencv\n",
    "2. Use mediapipe to process this data and extract the needed landmarks \n",
    "3. Train this data with N-Net \n",
    "4. Test the trained results\n",
    "5. Pass static images to the classifier \n",
    "\n",
    "WEBCAM -> MEDIAPIPE LMs -> Preprocessed LMS -> MODEL Classifier -> Rock, paper scissors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up basic utilities \n",
    "\n",
    "### Initializing variables for saving dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ead8189fa437>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmp_drawing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmp_hands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "# Mediapipe hand tools \n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save dataset \n",
    "save_dir = 'hand_landmarks'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_landmarks = 3000  \n",
    "test_landmarks = 200 \n",
    "images_per_class = total_landmarks // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = []\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List to store landmarks together with labels\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam Access\n",
    "\n",
    "### Saving data in numpy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with mp_hands.Hands(static_image_mode= False, max_num_hands=2, min_detection_confidence=0.45) as hands:\n",
    "    while True: \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False \n",
    "        results = hands.process(image)\n",
    "        \n",
    "        image.flags.writeable = True \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        # Drawing the hand landmarks \n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks\n",
    "                                          , mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                image_height, image_width, _ = image.shape\n",
    "                \n",
    "                landmark_list = []\n",
    "                \n",
    "                for landmark in hand_landmarks.landmark: \n",
    "                    landmark_x = landmark.x * image_width\n",
    "                    landmark_y = landmark.y * image_height\n",
    "                    \n",
    "                    landmark_list.extend([landmark_x, landmark_y, landmark.z])\n",
    "                landmarks.append(landmark_list)\n",
    "                print(landmarks)\n",
    "        \n",
    "        cv2.imshow('Rock Paper Scissors Classifier', image)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('r') and labels.count(0) <= images_per_class:\n",
    "            \n",
    "            labels.append(0)\n",
    "            if labels.count(0) == images_per_class:\n",
    "                print(\"Last label for this class\")\n",
    "            else:\n",
    "                np.save(os.path.join(save_dir, f'rock_{len(labels)}.npy'), landmarks[-1])\n",
    "                print(\"Saved Rock Hand Landmark successfully!\")\n",
    "                \n",
    "        elif key == ord('p') and labels.count(1) <= images_per_class:\n",
    "            \n",
    "            labels.append(1)\n",
    "            \n",
    "            if labels.count(1) == images_per_class:\n",
    "                print(\"Last label for this class\")\n",
    "            else:\n",
    "                np.save(os.path.join(save_dir, f'paper_{len(labels)}.npy'), landmarks[-1])\n",
    "                print(\"Saved Paper Hand Landmark successfully!\")\n",
    "                \n",
    "        if key == ord('s') and labels.count(2) <= images_per_class:\n",
    "            \n",
    "            labels.append(2)\n",
    "            \n",
    "            if labels.count(2) == images_per_class:\n",
    "                print(\"Last label for this class\")\n",
    "            else:\n",
    "                np.save(os.path.join(save_dir, f'scissors_{len(labels)}.npy'), landmarks[-1])\n",
    "                print(\"Saved Scissors Hand Landmark successfully!\")\n",
    "            \n",
    "        if len(labels) >= total_landmarks:\n",
    "            break\n",
    "        \n",
    "        if key == ord('x'): \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you carry out the appropriate preprocessing steps for the javascript mediapipe\n",
    "\n",
    "1. Normalizing and making a single array: Multiply the landmark x and y with the image width and heigth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hand_landmarks\\class_0\n",
      "hand_landmarks\\class_1\n",
      "hand_landmarks\\class_2\n"
     ]
    }
   ],
   "source": [
    "for label in range(3):\n",
    "    class_dir = os.path.join(save_dir, 'class_{}'.format(label))\n",
    "    print(class_dir)\n",
    "    for file_name in os.listdir(class_dir):\n",
    "        file_path = os.path.join(class_dir, file_name)\n",
    "        landmark = np.load(file_path)\n",
    "        labels.append(label)\n",
    "        data.append(landmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting more data with Static Images for Training \n",
    "\n",
    "    - Extract landmarks from all the images \n",
    "    - Save the landmarks to a numpy file, and create a new directory called hand_landmarks_2 \n",
    "    - Add the data to the existing data\n",
    "    - Retrain the model with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IMAGE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FILES = os.listdir('rock_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WIN_20230804_12_17_40_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_40_Pro.jpg',\n",
       " 'WIN_20230804_12_17_41_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_41_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_41_Pro (4).jpg',\n",
       " 'WIN_20230804_12_17_41_Pro.jpg',\n",
       " 'WIN_20230804_12_17_43_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_43_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_43_Pro.jpg',\n",
       " 'WIN_20230804_12_17_44_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_44_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_44_Pro.jpg',\n",
       " 'WIN_20230804_12_17_45_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_45_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_45_Pro.jpg',\n",
       " 'WIN_20230804_12_17_46_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_46_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_46_Pro.jpg',\n",
       " 'WIN_20230804_12_17_47_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_47_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_47_Pro (4).jpg',\n",
       " 'WIN_20230804_12_17_47_Pro.jpg',\n",
       " 'WIN_20230804_12_17_48_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_48_Pro.jpg',\n",
       " 'WIN_20230804_12_17_49_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_49_Pro.jpg',\n",
       " 'WIN_20230804_12_17_50_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_50_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_50_Pro (4).jpg',\n",
       " 'WIN_20230804_12_17_50_Pro.jpg',\n",
       " 'WIN_20230804_12_17_51_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_51_Pro.jpg',\n",
       " 'WIN_20230804_12_17_52_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_52_Pro.jpg',\n",
       " 'WIN_20230804_12_17_53_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_53_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_53_Pro (4).jpg',\n",
       " 'WIN_20230804_12_17_53_Pro.jpg',\n",
       " 'WIN_20230804_12_17_54_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_54_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_54_Pro (4).jpg',\n",
       " 'WIN_20230804_12_17_54_Pro.jpg',\n",
       " 'WIN_20230804_12_17_55_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_55_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_55_Pro (4).jpg',\n",
       " 'WIN_20230804_12_17_55_Pro.jpg',\n",
       " 'WIN_20230804_12_17_56_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_56_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_56_Pro (4).jpg',\n",
       " 'WIN_20230804_12_17_56_Pro.jpg',\n",
       " 'WIN_20230804_12_17_57_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_57_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_57_Pro.jpg',\n",
       " 'WIN_20230804_12_17_58_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_58_Pro.jpg',\n",
       " 'WIN_20230804_12_17_59_Pro (2).jpg',\n",
       " 'WIN_20230804_12_17_59_Pro (3).jpg',\n",
       " 'WIN_20230804_12_17_59_Pro.jpg',\n",
       " 'WIN_20230804_12_18_00_Pro.jpg',\n",
       " 'WIN_20230804_12_18_01_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_01_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_01_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_01_Pro.jpg',\n",
       " 'WIN_20230804_12_18_02_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_02_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_02_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_02_Pro.jpg',\n",
       " 'WIN_20230804_12_18_03_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_03_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_03_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_03_Pro (5).jpg',\n",
       " 'WIN_20230804_12_18_03_Pro.jpg',\n",
       " 'WIN_20230804_12_18_04_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_04_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_04_Pro.jpg',\n",
       " 'WIN_20230804_12_18_05_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_05_Pro.jpg',\n",
       " 'WIN_20230804_12_18_06_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_06_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_06_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_06_Pro.jpg',\n",
       " 'WIN_20230804_12_18_07_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_07_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_07_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_07_Pro.jpg',\n",
       " 'WIN_20230804_12_18_08_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_08_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_08_Pro.jpg',\n",
       " 'WIN_20230804_12_18_09_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_09_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_09_Pro.jpg',\n",
       " 'WIN_20230804_12_18_10_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_10_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_10_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_10_Pro.jpg',\n",
       " 'WIN_20230804_12_18_11_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_11_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_11_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_11_Pro.jpg',\n",
       " 'WIN_20230804_12_18_12_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_12_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_12_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_12_Pro.jpg',\n",
       " 'WIN_20230804_12_18_13_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_13_Pro.jpg',\n",
       " 'WIN_20230804_12_18_14_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_14_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_14_Pro.jpg',\n",
       " 'WIN_20230804_12_18_15_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_15_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_15_Pro.jpg',\n",
       " 'WIN_20230804_12_18_16_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_16_Pro.jpg',\n",
       " 'WIN_20230804_12_18_17_Pro.jpg',\n",
       " 'WIN_20230804_12_18_18_Pro.jpg',\n",
       " 'WIN_20230804_12_18_19_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_19_Pro.jpg',\n",
       " 'WIN_20230804_12_18_20_Pro.jpg',\n",
       " 'WIN_20230804_12_18_21_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_21_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_21_Pro.jpg',\n",
       " 'WIN_20230804_12_18_22_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_22_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_22_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_22_Pro.jpg',\n",
       " 'WIN_20230804_12_18_23_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_23_Pro.jpg',\n",
       " 'WIN_20230804_12_18_24_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_24_Pro.jpg',\n",
       " 'WIN_20230804_12_18_25_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_25_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_25_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_25_Pro (5).jpg',\n",
       " 'WIN_20230804_12_18_25_Pro.jpg',\n",
       " 'WIN_20230804_12_18_26_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_26_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_26_Pro.jpg',\n",
       " 'WIN_20230804_12_18_27_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_27_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_27_Pro.jpg',\n",
       " 'WIN_20230804_12_18_28_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_28_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_28_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_28_Pro (5).jpg',\n",
       " 'WIN_20230804_12_18_28_Pro (6).jpg',\n",
       " 'WIN_20230804_12_18_28_Pro.jpg',\n",
       " 'WIN_20230804_12_18_29_Pro.jpg',\n",
       " 'WIN_20230804_12_18_44_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_44_Pro.jpg',\n",
       " 'WIN_20230804_12_18_45_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_45_Pro.jpg',\n",
       " 'WIN_20230804_12_18_46_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_46_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_46_Pro.jpg',\n",
       " 'WIN_20230804_12_18_47_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_47_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_47_Pro.jpg',\n",
       " 'WIN_20230804_12_18_48_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_48_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_48_Pro.jpg',\n",
       " 'WIN_20230804_12_18_49_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_49_Pro.jpg',\n",
       " 'WIN_20230804_12_18_50_Pro.jpg',\n",
       " 'WIN_20230804_12_18_51_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_51_Pro.jpg',\n",
       " 'WIN_20230804_12_18_52_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_52_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_52_Pro.jpg',\n",
       " 'WIN_20230804_12_18_54_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_54_Pro.jpg',\n",
       " 'WIN_20230804_12_18_55_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_55_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_55_Pro.jpg',\n",
       " 'WIN_20230804_12_18_56_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_56_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_56_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_56_Pro.jpg',\n",
       " 'WIN_20230804_12_18_57_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_57_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_57_Pro.jpg',\n",
       " 'WIN_20230804_12_18_58_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_58_Pro (3).jpg',\n",
       " 'WIN_20230804_12_18_58_Pro (4).jpg',\n",
       " 'WIN_20230804_12_18_58_Pro.jpg',\n",
       " 'WIN_20230804_12_18_59_Pro (2).jpg',\n",
       " 'WIN_20230804_12_18_59_Pro.jpg',\n",
       " 'WIN_20230804_12_19_00_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_00_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_00_Pro.jpg',\n",
       " 'WIN_20230804_12_19_01_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_01_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_01_Pro (4).jpg',\n",
       " 'WIN_20230804_12_19_01_Pro.jpg',\n",
       " 'WIN_20230804_12_19_02_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_02_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_02_Pro (4).jpg',\n",
       " 'WIN_20230804_12_19_02_Pro.jpg',\n",
       " 'WIN_20230804_12_19_03_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_03_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_03_Pro (4).jpg',\n",
       " 'WIN_20230804_12_19_03_Pro (5).jpg',\n",
       " 'WIN_20230804_12_19_03_Pro.jpg',\n",
       " 'WIN_20230804_12_19_04_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_04_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_04_Pro (4).jpg',\n",
       " 'WIN_20230804_12_19_04_Pro.jpg',\n",
       " 'WIN_20230804_12_19_05_Pro.jpg',\n",
       " 'WIN_20230804_12_19_06_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_06_Pro.jpg',\n",
       " 'WIN_20230804_12_19_07_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_07_Pro.jpg',\n",
       " 'WIN_20230804_12_19_08_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_08_Pro.jpg',\n",
       " 'WIN_20230804_12_19_09_Pro.jpg',\n",
       " 'WIN_20230804_12_19_10_Pro.jpg',\n",
       " 'WIN_20230804_12_19_12_Pro.jpg',\n",
       " 'WIN_20230804_12_19_13_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_13_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_13_Pro.jpg',\n",
       " 'WIN_20230804_12_19_14_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_14_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_14_Pro (4).jpg',\n",
       " 'WIN_20230804_12_19_14_Pro.jpg',\n",
       " 'WIN_20230804_12_19_15_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_15_Pro.jpg',\n",
       " 'WIN_20230804_12_19_17_Pro.jpg',\n",
       " 'WIN_20230804_12_19_18_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_18_Pro (3).jpg',\n",
       " 'WIN_20230804_12_19_18_Pro.jpg',\n",
       " 'WIN_20230804_12_19_19_Pro.jpg',\n",
       " 'WIN_20230804_12_19_20_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_20_Pro.jpg',\n",
       " 'WIN_20230804_12_19_22_Pro.jpg',\n",
       " 'WIN_20230804_12_19_23_Pro.jpg',\n",
       " 'WIN_20230804_12_19_24_Pro (2).jpg',\n",
       " 'WIN_20230804_12_19_24_Pro.jpg']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '../' + save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../hand_landmarks'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Landmarks From Static Images \n",
    "\n",
    "### Some images were gotten from the webcam live feed, and some others were gotten from dataset online and from camera shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-867f4d00fbb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmp_drawing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmp_drawing_styles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_styles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmp_hands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# For static images:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For static images:\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "    for idx, file in enumerate(IMAGE_FILES):\n",
    "    # Read an image, flip it around y-axis for correct handedness output (see\n",
    "        # above).\n",
    "        idx += 2002\n",
    "        image = cv2.imread(file)\n",
    "        #image = cv2.flip(cv2.imread(file), 1)\n",
    "        # Convert the BGR image to RGB before processing.\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if not results.multi_hand_landmarks:\n",
    "            print(f\"No image detected - {file}\")\n",
    "            continue\n",
    "        image_height, image_width, _ = image.shape\n",
    "        annotated_image = image.copy()\n",
    "        \n",
    "        \n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            #print('hand_landmarks:', hand_landmarks)\n",
    "\n",
    "            landmark_list = [] \n",
    "            for landmark in hand_landmarks.landmark: \n",
    "                landmark_x = landmark.x * image_width\n",
    "                landmark_y = landmark.y * image_height\n",
    "\n",
    "                landmark_list.extend([landmark_x, landmark_y, landmark.z])\n",
    "\n",
    "            np.save(os.path.join(save_directory, f'rock_{idx}.npy'), landmark_list)\n",
    "            print(\"Saved Rock Hand Landmark successfully!\")\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "              annotated_image,\n",
    "              hand_landmarks,\n",
    "              mp_hands.HAND_CONNECTIONS,\n",
    "              mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "              mp_drawing_styles.get_default_hand_connections_style())\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(IMAGE_FILES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssffff\\Desktop\\One for all\\Machine Learning Work\\Machine Learning projects\\RPS\\Model\\rock_images\n"
     ]
    }
   ],
   "source": [
    "%cd rock_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
